{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: US Transportation\n",
    "## Authors: Yasmine Thandi, Kyle Truong, Bin Xu\n",
    "**Original Dataset Source: Monthly Transportation Statistics (Updated 2024). Kaggle Data Science Platform. https://www.kaggle.com/datasets/utkarshx27/monthly-transportation-statistics/data**\n",
    "\n",
    "**Modified Dataset: https://raw.githubusercontent.com/HenryCROSS/eecs3401_final_project/main/data/Monthly_Transportation_Statistics.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transportation Dataset Description\n",
    "From the original dataset, any data prior to 1967 was removed, due to there being an insufficient amount of data recorded by The Bureau of Transportation Statistics.\n",
    "\n",
    "We believe that most of the data provided to us is excessive and isn't required for the task we want to focus on. Therefore we reduced our 136 unique attributes to 26 that we thought were useful for our model.\n",
    "### Attributes Used:\n",
    "1. **Date** - The date the data was recorded (Typically the first day of each month at 12:00AM)\n",
    "1. **Transit Ridership - Other Transit Modes - Adjusted** - Total number of riders on other transit modes.\n",
    "1. **Transit Ridership - Fixed Route Bus - Adjusted** - Total number of riders on any bus routes.\n",
    "1. **Transit Ridership - Urban Rail - Adjusted** - Total number of riders on any methods of urban rail (i.e. Subway, Local Trains, etc.)\n",
    "1. **Freight Rail Intermodal Units** - Number of freight cars used per month.\n",
    "1. **Freight Rail Carloads** - Number of freight cars with cargo loaded per month.\n",
    "1. **Highway Vehicle Miles Traveled - All Systems** - Total combined miles travelled on a highway.\n",
    "1. **Highway Fuel Price - Regular Gasoline** - Price of regular gasoline per gallon.\n",
    "1. **Highway Fuel Price - On-highway Diesel** - Price of diesel per gallon.\n",
    "1. **Personal Spending on Transportation - Transportation Services - Seasonally Adjusted** - Average monthly cost on transportation.\n",
    "1. **Personal Spending on Transportation - Gasoline and Other Energy Goods - Seasonally Adjusted** - Average monthly on gasoline, diesel or electricity.\n",
    "1. **Personal Spending on Transportation - Motor Vehicles and Parts - Seasonally Adjusted** - Average monthly spending on autoshops, repair parts and services.\n",
    "1. **Passenger Rail Passengers** - Number of passengers who use the trains every month\n",
    "1. **Transportation Services Index - Freight** - Month to month performance output measure of freight services\n",
    "1. **Transportation Services Index - Passenger** - Month to month performance output measure of passenger services\n",
    "1. **Real Gross Domestic Product - Seasonally Adjusted** - Monetary value of all transportation services\n",
    "1. **U.S.-Canada Incoming Person Crossings** - Number of people entering the United States from Canada\n",
    "1. **U.S.-Canada Incoming Truck Crossings** - Number of trucks entering the United States from Canada\n",
    "1. **U.S.-Mexico Incoming Person Crossings** - Number of people entering the United States from Mexico\n",
    "1. **U.S.-Mexico Incoming Truck Crossings** - Number of trucks entering the United States from Mexico\n",
    "1. **U.S. Airline Traffic - Domestic - Non Seasonally Adjusted** - Amount of airline traffic travelling within the United States\n",
    "1. **U.S. Airline Traffic - Total - Non Seasonally Adjusted** - Amount of airline traffic travelling collectively involving the United States\n",
    "1. **U.S. Airline Traffic - International - Non Seasonally Adjusted** - Amount of airline traffic travelling in and out of the United States\n",
    "1. **Transborder - Total North American Freight** - Total freight travelled across North America\n",
    "1. **Transborder - U.S. - Mexico Freight** - Total freight travelled across the US-Mexico border into the United States\n",
    "1. **Transborder - U.S. - Canada Freight** - Total freight travelled across the US-Canada border into the United States\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Look at the big picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame the problem\n",
    "1. Supervised learning.\n",
    "2. A regression task â€“ predict a value.\n",
    "3. Batch learning \n",
    "    - Small data set\n",
    "    - No need to continuously adjust any incoming data because the last data recorded was in December, 2023\n",
    "\n",
    "### Look at the big picture\n",
    "Predictions will be used to inform operators in the US about future transportation metrics by using previous data on border crossings, ridership count, freight values, prices and revenue. We will be predicting the future cost of transportation and the future size of ridership. This will help with resource allocation, and predicting the future demand of transportation services for the operators. By understanding the relationship between the demand and revenue in the data set, we will provide a suitable budget as a future reference to operators to assist with optimizing pricing strategies for transportation services. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# you can install missing library using pip install numpy \n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/HenryCROSS/eecs3401_final_project/main/data/Monthly_Transportation_Statistics.csv\"\n",
    "data = pd.read_csv(url, sep=',')\n",
    "data_bak = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1\n",
    "We decided at this point in time to reduce the number of attributes in our dataset, as we believe it would help optimize our workflow moving forwards. As mentioned above, these points of data were selected because we believe that they would be useful to our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeep = [\"Date\", \"Transit Ridership - Other Transit Modes - Adjusted\", \"Transit Ridership - Fixed Route Bus - Adjusted\", \"Transit Ridership - Urban Rail - Adjusted\", \"Freight Rail Intermodal Units\", \"Freight Rail Carloads\",  \"State and Local Government Construction Spending - Total\", \"Highway Fuel Price - Regular Gasoline\", \n",
    "          \"Highway Fuel Price - On-highway Diesel\", \"Personal Spending on Transportation - Transportation Services - Seasonally Adjusted\", \"Personal Spending on Transportation - Gasoline and Other Energy Goods - Seasonally Adjusted\", \"Personal Spending on Transportation - Motor Vehicles and Parts - Seasonally Adjusted\",\n",
    "          \"Passenger Rail Passengers\", \"Transportation Services Index - Freight\", \"Transportation Services Index - Passenger\", \"Real Gross Domestic Product - Seasonally Adjusted\", \"U.S.-Canada Incoming Person Crossings\", \"U.S.-Canada Incoming Truck Crossings\", \"U.S.-Mexico Incoming Person Crossings\", \n",
    "          \"U.S.-Mexico Incoming Truck Crossings\", \"U.S. Airline Traffic - Domestic - Non Seasonally Adjusted\", \"U.S. Airline Traffic - Total - Non Seasonally Adjusted\", \"U.S. Airline Traffic - International - Non Seasonally Adjusted\", \"Transborder - Total North American Freight\", \"Transborder - U.S. - Mexico Freight\",\"Transborder - U.S. - Canada Freight\"]\n",
    "data = data[tokeep]\n",
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we implement the info() function to get a description of our data, and the number of non-null attributes. We have determined that it would be best to remove Highway Vehicle Miles Traveled - All Systems since it only has 50 non-null attributes. This helps us scale our data from 2017 - 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore and visualize the data to gain insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to create custom heading titles to make the following graphs in our data visualization more readable. Here is the key to the following acronyms of the attribute names:\n",
    "\n",
    "- TR = Transit Ridership, FR = Freight Rail, H = Highway, V = Vehicle, F = Fuel, P = Price, PST = Personal Spending on Transportation, TSI = Transportation Sevices Index, Pass = Passenger, PC = Person Crossings, TC = Truck Crossings, Mex = Mexico, AT = Airline Traffic, TB = Transborder\n",
    "- AS = All Systems, A = Adjusted, SA = Seasonally Adjusted, NSA = Non Seasonally Adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom headers\n",
    "custom_headers = [\n",
    "    \"Date\",\n",
    "    \"TROtherTransit(A)\",\n",
    "    \"TRFixedRouteBus(A)\",\n",
    "    \"TRUrbanRail(A)\",\n",
    "    \"FRIntermodalUnits\",\n",
    "    \"FRCarloads\",\n",
    "    \"HFP-RegGas\",\n",
    "    \"HFP-HDiesel\",\n",
    "    \"PST-TransServ(SA)\",\n",
    "    \"PST-EnergyGoods(SA)\",\n",
    "    \"PST-AutoServ(SA)\",\n",
    "    \"PassRailPass\",\n",
    "    \"TSI-Freight\",\n",
    "    \"TSI-Pass\",\n",
    "    \"RealGDP(SA)\",\n",
    "    \"US-CA PC\",\n",
    "    \"US-CA TC\",\n",
    "    \"US-Mex PC\",\n",
    "    \"US-Mex TC\",\n",
    "    \"US AT - Domestic(NSA)\",\n",
    "    \"US AT - Total(NSA)\",\n",
    "    \"US AT - International(NSA)\",\n",
    "    \"TB - TotalFreight\",\n",
    "    \"TB - US-MexFreight\",\n",
    "    \"TB - US-CAFreight\"\n",
    "]\n",
    "\n",
    "# Load the dataset with custom headers and selected columns\n",
    "data = pd.read_csv(url, usecols=tokeep)\n",
    "data.columns = custom_headers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the describe() method to see a summary of the numerical attributes. This way we can clean our data more efficiently by replacing missing data with median/average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Plot a histogram of the data using hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(18, 16))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram on combined target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a histogram on our target value, which is transit ridership, by combining the data from TROtherTransit(A), TRFixedRouteBus(A) and TRUrbanRail(A). This is done so that we can use the graph to interpret what method of feature scaling we would like to use. Looking at the graph, the data seems to be skewed to the left. However, to be completely sure regarding whether we should use the min-max scaler or not, we want to determine whether there is normalization here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TRTotal'] = data['TROtherTransit(A)']+data['TRFixedRouteBus(A)']+data['TRUrbanRail(A)']\n",
    "\n",
    "data['TRTotal'].hist(bins=50, figsize=(14, 10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data obtained from data['TRTotal']\n",
    "TotalTRData = data['TRTotal']\n",
    "\n",
    "# Convert the data to a numpy array and sort the array\n",
    "TotalTRData = np.array(TotalTRData)\n",
    "\n",
    "TotalTRData_sorted = np.sort(TotalTRData)\n",
    "\n",
    "# Create sample data and sort it\n",
    "new_data = np.random.normal(loc=0, scale=1, size=len(TotalTRData))\n",
    "\n",
    "new_data_sorted = np.sort(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a Q-Q plot to determine whether the following data is an example of normal distributon. The data below does slightly follow a line, so we will try to use both feature scaling methods (min-max and a standard scaler) to see which works best in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Q-Q plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(new_data_sorted, TotalTRData_sorted)\n",
    "plt.plot([np.min(new_data_sorted), np.max(new_data_sorted)],\n",
    "         [np.min(TotalTRData_sorted), np.max(TotalTRData_sorted)], color='red')\n",
    "plt.title('Q-Q Plot')\n",
    "plt.xlabel('Ordered Values (new_data)')\n",
    "plt.ylabel('Ordered Values (TotalTRData)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Plot a Box Plot of the data using boxplot() of Highway Fuel Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of Highway Fuel Prices \n",
    "# Compares the distribution of regular gasoline against highway diesel prices so that operators can make informed decisions regarding budgeting \n",
    "# and pricing on transportation services after examining the interquartile range (the spread of the prices)\n",
    "plt.figure(figsize=(12, 8))  \n",
    "sns.boxplot(data=data[['HFP-RegGas', 'HFP-HDiesel']])\n",
    "plt.title('Distribution of Highway Fuel Prices')\n",
    "plt.ylabel('Price (per gallon)')\n",
    "plt.xlabel('Fuel Type')\n",
    "plt.xticks(ticks=[0, 1], labels=['Regular Gasoline', 'On-highway Diesel'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Plot a histogram of the data using hist() of Personal Spendings on Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Personal Spendings on Transportation\n",
    "# Examines personal spending on transportation services, motor vehicles and gas so that operators can make informed decisions regarding \n",
    "# budgeting and pricing on transportation and adjust prices accprding to individual and customer expenditures\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.histplot(data=data[['PST-TransServ(SA)',\n",
    "                        'PST-EnergyGoods(SA)',\n",
    "                        'PST-AutoServ(SA)']], bins=20, kde=True)\n",
    "plt.title('Distribution of Personal Spending on Transportation')\n",
    "plt.xlabel('Spending (USD)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(['Transportation Services', 'Gasoline and Energy Goods', 'Motor Vehicles and Parts'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Plot a Time Series Analysis of Transit Ridership "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Time Series Analysis of Transit Ridership : Plots the trend of transit overtime\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Date', y='TRFixedRouteBus(A)', data=data)\n",
    "sns.lineplot(x='Date', y='TRUrbanRail(A)', data=data)\n",
    "plt.title('Transit Ridership Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Ridership')\n",
    "plt.legend(['Fixed Route Bus', 'Urban Rail'])\n",
    "plt.xticks(range(660,len(data), 12), rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Plot a Heat Map Using heatmap() to Compare GDP with Different Transportation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for GDP vs. Transportation Metrics \n",
    "# Assists with determining which transportation metrics are strongly correlated with the GDP and help operators make adjustmets to transportation service plans\n",
    "selected_columns = ['RealGDP(SA)',\n",
    "                   'TB - TotalFreight',\n",
    "                   'US AT - Total(NSA)',\n",
    "                   'TSI-Freight']\n",
    "\n",
    "correlation_matrix = data[selected_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap: GDP vs. Transportation Metrics')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for correlations between the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Check for correlation between attributes using sns.pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for correlation between attributes using sns.pairplot.\n",
    "#sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Look for correlations using pearson correlation coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr(numeric_only=True)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at correlations with regards to our target..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"TROtherTransit(A)\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"TRFixedRouteBus(A)\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"TRUrbanRail(A)\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare the data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Handle the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the date since it is not needed for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=['Date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis='rows', thresh=int(0.05 * data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with standard Scaler and replace the empty value to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = data.select_dtypes(include='number').columns.to_list()\n",
    "\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='constant', fill_value=0), StandardScaler())\n",
    "\n",
    "preprocessing = ColumnTransformer([('num', num_pipeline, num_cols)],\n",
    "                                    remainder='passthrough')\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepared = preprocessing.fit_transform(data)\n",
    "\n",
    "feature_names=preprocessing.get_feature_names_out()\n",
    "data_prepared = pd.DataFrame(data=data_prepared, columns=feature_names)\n",
    "data_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Select a model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [\"num__TROtherTransit(A)\", \"num__TRFixedRouteBus(A)\", \"num__TRUrbanRail(A)\"]\n",
    "\n",
    "y = data_prepared.drop(features, axis=1)\n",
    "X = data_prepared[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Linear Regression model without any regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_predict = lr_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "lr_mse=mse(y_test, lr_y_predict)\n",
    "lr_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'lr_model' is your best performing trained linear regression model\n",
    "lr_y_predict = lr_model.predict(X_test)  # X is your feature data\n",
    "plt.scatter(lr_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Linear Regression model using Ridge regularization with alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "RidgeRegression = Ridge()\n",
    "param_grid = {'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500]}\n",
    "RidgeRegression = GridSearchCV(RidgeRegression, param_grid)\n",
    "ridge_model = RidgeRegression.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_y_predict = ridge_model.predict(X_test)\n",
    "ridge_mse = mse(y_test, Ridge_y_predict)\n",
    "\n",
    "print(f'Ridge Regression MSE: {ridge_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_y_predict = ridge_model.predict(X_test)\n",
    "plt.scatter(Ridge_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Linear Regression model using Lasso regularization with alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "LassoRegression = Lasso()\n",
    "param_grid = {'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500]}\n",
    "LassoRegression = GridSearchCV(LassoRegression, param_grid)\n",
    "lasso_model = LassoRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_y_predict = lasso_model.predict(X_test)\n",
    "lasso_mse=mse(y_test, Lasso_y_predict)\n",
    "\n",
    "print(f'Lasso Regression MSE: {lasso_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_y_predict = lasso_model.predict(X_test)\n",
    "plt.scatter(Lasso_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "dt_y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "dt_mse=mse(y_test, dt_y_pred)\n",
    "dt_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dt_y_pred, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with Min Max Scaler and replace the empty value to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "num_cols = data.select_dtypes(include='number').columns.to_list()\n",
    "\n",
    "#create pipelines for numeric columns\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='constant', fill_value=0), MinMaxScaler())\n",
    "\n",
    "preprocessing = ColumnTransformer([('num', num_pipeline, num_cols)],\n",
    "                                    remainder='passthrough')\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepared = preprocessing.fit_transform(data)\n",
    "\n",
    "feature_names=preprocessing.get_feature_names_out()\n",
    "data_prepared = pd.DataFrame(data=data_prepared, columns=feature_names)\n",
    "data_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [\"num__TROtherTransit(A)\", \"num__TRFixedRouteBus(A)\", \"num__TRUrbanRail(A)\"]\n",
    "\n",
    "y = data_prepared.drop(features, axis=1)\n",
    "X = data_prepared[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_minmax_model = LinearRegression()\n",
    "\n",
    "lr_minmax_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_minmax_y_predict = lr_minmax_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "lr_minmax_mse=mse(y_test, lr_minmax_y_predict)\n",
    "lr_minmax_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lr_minmax_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desicion Tree with min-max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "dt_minmax_y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "dt_minmax_mse=mse(y_test, dt_minmax_y_pred)\n",
    "dt_minmax_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dt_minmax_y_pred, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Linear Regression model using Ridge regularization with alpha=1 and MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "RidgeRegression = Ridge()\n",
    "param_grid = {'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500]}\n",
    "RidgeRegression = GridSearchCV(RidgeRegression, param_grid)\n",
    "ridge_minmax_model = RidgeRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_minmax_y_predict = ridge_minmax_model.predict(X_test)\n",
    "ridge_minmax_mse = mse(y_test, Ridge_minmax_y_predict)\n",
    "\n",
    "print(f'Ridge Regression MSE: {ridge_minmax_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Ridge_minmax_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Linear Regression model using Lasso regularization with alpha=1 and MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "LassoRegression = Lasso()\n",
    "param_grid = {'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500]}\n",
    "LassoRegression = GridSearchCV(LassoRegression, param_grid)\n",
    "lasso_minmax_model = LassoRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_minmax_y_predict = lasso_minmax_model.predict(X_test)\n",
    "lasso_minmax_mse=mse(y_test, Lasso_minmax_y_predict)\n",
    "\n",
    "print(f'Lasso Regression MSE: {lasso_minmax_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Lasso_minmax_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with standard Scaler, PolynomialFeatures with degree = 3 and replace the empty value to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = data.select_dtypes(include='number').columns.to_list()\n",
    "\n",
    "#create pipelines for numeric columns\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='constant', fill_value=0), StandardScaler(),\n",
    "                             PolynomialFeatures(degree=3))\n",
    "\n",
    "preprocessing = ColumnTransformer([('num', num_pipeline, num_cols)],\n",
    "                                    remainder='passthrough')\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepared = preprocessing.fit_transform(data)\n",
    "\n",
    "feature_names=preprocessing.get_feature_names_out()\n",
    "data_prepared = pd.DataFrame(data=data_prepared, columns=feature_names)\n",
    "data_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [\"num__TROtherTransit(A)\", \"num__TRFixedRouteBus(A)\", \"num__TRUrbanRail(A)\"]\n",
    "\n",
    "y = data_prepared.drop(features, axis=1)\n",
    "X = data_prepared[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pr_model = LinearRegression()\n",
    "\n",
    "pr_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_y_predict = pr_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "pr_mse=mse(y_test, pr_y_predict)\n",
    "pr_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pr_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### decision tree with Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "decision_tree = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "dt_pr_y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "dt_pr_mse=mse(y_test, dt_pr_y_pred)\n",
    "dt_pr_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dt_pr_y_pred, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Polynomial Regression model using Lasso regularization with alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "LassoRegression = Lasso()\n",
    "param_grid = {'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500]}\n",
    "LassoRegression = GridSearchCV(LassoRegression, param_grid)\n",
    "pr_lasso_model = LassoRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_Lasso_y_predict = pr_lasso_model.predict(X_test)\n",
    "pr_lasso_mse=mse(y_test, pr_Lasso_y_predict)\n",
    "\n",
    "print(f'Lasso Regression MSE: {pr_lasso_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pr_Lasso_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Polynomial Regression model using Ridge regularization with alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "RidgeRegression = Ridge()\n",
    "param_grid = {'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 500]}\n",
    "RidgeRegression = GridSearchCV(RidgeRegression, param_grid)\n",
    "pr_ridge_model = RidgeRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_Ridge_y_predict = pr_ridge_model.predict(X_test)\n",
    "pr_ridge_mse = mse(y_test, pr_Ridge_y_predict)\n",
    "\n",
    "print(f'Ridge Regression MSE: {pr_ridge_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pr_Ridge_y_predict, y_test)  # y is your actual target values\n",
    "plt.xlabel(\"TR Predicted Values\")\n",
    "plt.ylabel(\"TR Actual Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Linear Regression MSE: {lr_mse}')\n",
    "print(f'Ridge Regression MSE: {ridge_mse}')\n",
    "print(f'Lasso Regression MSE: {lasso_mse}')\n",
    "print(f'Decision Tree MSE: {dt_mse}')\n",
    "print()\n",
    "print(f'Linear Regression with MinMaxScaler MSE: {lr_minmax_mse}')\n",
    "print(f'Ridge Regression with MinMaxScaler MSE: {ridge_minmax_mse}')\n",
    "print(f'Lasso Regression with MinMaxScaler MSE: {lasso_minmax_mse}')\n",
    "print(f'Decision Tree with MinMaxScaler MSE: {dt_minmax_mse}')\n",
    "print()\n",
    "print(f'Polynomail Regression MSE: {pr_mse}')\n",
    "print(f'Ridge Regression with Polynomail Regression MSE: {pr_ridge_mse}')\n",
    "print(f'Lasso Regression with Polynomail Regression MSE: {pr_lasso_mse}')\n",
    "print(f'Decision Tree with Polynomail Regression MSE: {dt_pr_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine-Tune Your Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
